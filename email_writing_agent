from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from PIL import Image
import io

# Represents your agent global state
class State(TypedDict):
    email_title: str
    email_body: str
    messages: Annotated[list, add_messages]

# StateGraph is your actual agent
graph_builder = StateGraph(State)

# Connect to your local Ollama endpoint by modifying the base URL.
from langchain_openai import ChatOpenAI
model_id = "llama3.2:latest"
base_url = "http://localhost:11434/v1"

llm = ChatOpenAI(model= model_id, base_url= base_url, temperature=0, max_tokens=4096, api_key="Not required with Ollama")

def chatbot(state: State):
    return {"messages": [llm.invoke(state["messages"])]}

graph_builder.add_node("chatbot", chatbot)
graph_builder.set_entry_point("chatbot")
graph_builder.set_finish_point("chatbot")

graph = graph_builder.compile()

request = """Write an email to Joan Smith from AmazingInternet asking politely a solution to a problem with my internet connection.
It has been failing everyday for at least 3 hours since 01/01/2025."""

thread_id = str(uuid.uuid4())
config = {
    "configurable": {
        # Checkpoints are accessed by thread_id
        "thread_id": thread_id,
    }
}

response = ""
events = graph.stream(
    {"messages": [("user", request)]}, config, stream_mode="values"
)

for event in events:
    response += event  # Accumulate all the events

# Print agent response
print(response)

# Print agent state snapshot
snapshot = graph.get_state(config)
print(snapshot)

# Optional: Save your graph diagram
image_bytes = research_agent.get_graph().draw_mermaid_png(
            draw_method=MermaidDrawMethod.API,
        )

image = Image.open(io.BytesIO(image_bytes))
image.save('output_graph.png') 
